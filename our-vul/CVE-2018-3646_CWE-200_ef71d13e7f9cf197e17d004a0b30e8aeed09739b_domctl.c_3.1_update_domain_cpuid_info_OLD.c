static int update_domain_cpuid_info(struct domain *d,
                                    const struct xen_domctl_cpuid *ctl)
{
    struct cpuid_policy *p = d->arch.cpuid;
    const struct cpuid_leaf leaf = { ctl->eax, ctl->ebx, ctl->ecx, ctl->edx };
    int old_vendor = p->x86_vendor;
    unsigned int old_7d0 = p->feat.raw[0].d, old_e8b = p->extd.raw[8].b;
    bool call_policy_changed = false; 

    




    switch ( ctl->input[0] )
    {
    case 0x00000000 ... ARRAY_SIZE(p->basic.raw) - 1:
        if ( ctl->input[0] == 4 &&
             ctl->input[1] >= ARRAY_SIZE(p->cache.raw) )
            return 0;

        if ( ctl->input[0] == 7 &&
             ctl->input[1] >= ARRAY_SIZE(p->feat.raw) )
            return 0;

        BUILD_BUG_ON(ARRAY_SIZE(p->xstate.raw) < 2);
        if ( ctl->input[0] == XSTATE_CPUID &&
             ctl->input[1] != 1 ) 
            return 0;
        break;

    case 0x40000000: case 0x40000100:
        

    case 0x80000000 ... 0x80000000 + ARRAY_SIZE(p->extd.raw) - 1:
        break;

    default:
        return 0;
    }

    
    switch ( ctl->input[0] )
    {
    case 0x00000000 ... ARRAY_SIZE(p->basic.raw) - 1:
        switch ( ctl->input[0] )
        {
        case 4:
            p->cache.raw[ctl->input[1]] = leaf;
            break;

        case 7:
            p->feat.raw[ctl->input[1]] = leaf;
            break;

        case XSTATE_CPUID:
            p->xstate.raw[ctl->input[1]] = leaf;
            break;

        default:
            p->basic.raw[ctl->input[0]] = leaf;
            break;
        }
        break;

    case 0x40000000:
        p->hv_limit = ctl->eax;
        break;

    case 0x40000100:
        p->hv2_limit = ctl->eax;
        break;

    case 0x80000000 ... 0x80000000 + ARRAY_SIZE(p->extd.raw) - 1:
        p->extd.raw[ctl->input[0] - 0x80000000] = leaf;
        break;
    }

    recalculate_cpuid_policy(d);

    switch ( ctl->input[0] )
    {
    case 0:
        call_policy_changed = (p->x86_vendor != old_vendor);
        break;

    case 1:
        if ( is_pv_domain(d) && ((levelling_caps & LCAP_1cd) == LCAP_1cd) )
        {
            uint64_t mask = cpuidmask_defaults._1cd;
            uint32_t ecx = p->basic._1c;
            uint32_t edx = p->basic._1d;

            




            if ( cpu_has_x2apic )
                ecx |= cpufeat_mask(X86_FEATURE_X2APIC);
            if ( cpu_has_htt )
                edx |= cpufeat_mask(X86_FEATURE_HTT);

            switch ( boot_cpu_data.x86_vendor )
            {
            case X86_VENDOR_INTEL:
                




                mask &= ((uint64_t)edx << 32) | ecx;

                if ( ecx & cpufeat_mask(X86_FEATURE_XSAVE) )
                    ecx = cpufeat_mask(X86_FEATURE_OSXSAVE);
                else
                    ecx = 0;
                edx = cpufeat_mask(X86_FEATURE_APIC);

                mask |= ((uint64_t)edx << 32) | ecx;
                break;

            case X86_VENDOR_AMD:
                mask &= ((uint64_t)ecx << 32) | edx;

                





                if ( ecx & cpufeat_mask(X86_FEATURE_XSAVE) )
                    ecx = cpufeat_mask(X86_FEATURE_OSXSAVE);
                else
                    ecx = 0;
                edx = cpufeat_mask(X86_FEATURE_APIC);

                mask |= ((uint64_t)ecx << 32) | edx;
                break;
            }

            d->arch.pv_domain.cpuidmasks->_1cd = mask;
        }
        break;

    case 6:
        if ( is_pv_domain(d) && ((levelling_caps & LCAP_6c) == LCAP_6c) )
        {
            uint64_t mask = cpuidmask_defaults._6c;

            if ( boot_cpu_data.x86_vendor == X86_VENDOR_AMD )
                mask &= (~0ULL << 32) | ctl->ecx;

            d->arch.pv_domain.cpuidmasks->_6c = mask;
        }
        break;

    case 7:
        if ( ctl->input[1] != 0 )
            break;

        if ( is_pv_domain(d) && ((levelling_caps & LCAP_7ab0) == LCAP_7ab0) )
        {
            uint64_t mask = cpuidmask_defaults._7ab0;
            uint32_t eax = ctl->eax;
            uint32_t ebx = p->feat._7b0;

            if ( boot_cpu_data.x86_vendor == X86_VENDOR_AMD )
                mask &= ((uint64_t)eax << 32) | ebx;

            d->arch.pv_domain.cpuidmasks->_7ab0 = mask;
        }

        



        call_policy_changed = (is_hvm_domain(d) &&
                               ((old_7d0 ^ p->feat.raw[0].d) &
                                cpufeat_mask(X86_FEATURE_IBRSB)));
        break;

    case 0xa:
        if ( boot_cpu_data.x86_vendor != X86_VENDOR_INTEL )
            break;

        
        if ( p->basic.pmu_version == 0 )
        {
            struct vcpu *v;

            for_each_vcpu ( d, v )
                vpmu_destroy(v);
        }
        break;

    case 0xd:
        if ( ctl->input[1] != 1 )
            break;

        if ( is_pv_domain(d) && ((levelling_caps & LCAP_Da1) == LCAP_Da1) )
        {
            uint64_t mask = cpuidmask_defaults.Da1;
            uint32_t eax = p->xstate.Da1;

            if ( boot_cpu_data.x86_vendor == X86_VENDOR_INTEL )
                mask &= (~0ULL << 32) | eax;

            d->arch.pv_domain.cpuidmasks->Da1 = mask;
        }
        break;

    case 0x80000001:
        if ( is_pv_domain(d) && ((levelling_caps & LCAP_e1cd) == LCAP_e1cd) )
        {
            uint64_t mask = cpuidmask_defaults.e1cd;
            uint32_t ecx = p->extd.e1c;
            uint32_t edx = p->extd.e1d;

            




            if ( cpu_has_cmp_legacy )
                ecx |= cpufeat_mask(X86_FEATURE_CMP_LEGACY);

            
            if ( p->x86_vendor != X86_VENDOR_AMD )
                edx &= ~CPUID_COMMON_1D_FEATURES;

            switch ( boot_cpu_data.x86_vendor )
            {
            case X86_VENDOR_INTEL:
                mask &= ((uint64_t)edx << 32) | ecx;
                break;

            case X86_VENDOR_AMD:
                mask &= ((uint64_t)ecx << 32) | edx;

                



                ecx = 0;
                edx = cpufeat_mask(X86_FEATURE_APIC);

                mask |= ((uint64_t)ecx << 32) | edx;
                break;
            }

            d->arch.pv_domain.cpuidmasks->e1cd = mask;
        }
        break;

    case 0x80000008:
        



        call_policy_changed = (is_hvm_domain(d) &&
                               ((old_e8b ^ p->extd.raw[8].b) &
                                cpufeat_mask(X86_FEATURE_IBPB)));
        break;
    }

    if ( call_policy_changed )
    {
        struct vcpu *v;

        for_each_vcpu( d, v )
            cpuid_policy_updated(v);
    }

    return 0;
}